{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11833263,"sourceType":"datasetVersion","datasetId":7434056}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-16T08:02:54.917748Z","iopub.execute_input":"2025-05-16T08:02:54.918039Z","iopub.status.idle":"2025-05-16T08:02:54.925348Z","shell.execute_reply.started":"2025-05-16T08:02:54.918019Z","shell.execute_reply":"2025-05-16T08:02:54.924591Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/medical-data/health_data_10000_chunk - health_data_10000_chunk.csv\n/kaggle/input/medical-data/df1.csv\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import pandas as pd\ndf1=pd.read_csv('/kaggle/input/medical-data/df1.csv')\ndf1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T08:02:56.566474Z","iopub.execute_input":"2025-05-16T08:02:56.567071Z","iopub.status.idle":"2025-05-16T08:02:56.661079Z","shell.execute_reply.started":"2025-05-16T08:02:56.567047Z","shell.execute_reply":"2025-05-16T08:02:56.660451Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"      Height (cm)  Weight (kg)   BMI  Previous gastrointestinal issues  \\\n0             173          120  40.1                                 1   \n1             183          110  32.8                                 0   \n2             170           97  33.6                                 1   \n3             163           75  28.2                                 1   \n4             172           85  28.7                                 0   \n...           ...          ...   ...                               ...   \n9226          187          107  30.6                                 1   \n9227          172           67  22.6                                 0   \n9228          162           89  33.9                                 1   \n9229          153          105  44.9                                 0   \n9230          198          120  30.6                                 1   \n\n      Frequency of bowel movements  Stool consistency (Bristol scale)  \\\n0                                6                                  2   \n1                               18                                  6   \n2                               17                                  4   \n3                               21                                  1   \n4                               20                                  7   \n...                            ...                                ...   \n9226                            15                                  6   \n9227                            19                                  6   \n9228                            13                                  4   \n9229                             9                                  2   \n9230                            12                                  6   \n\n      Presence of bloating  Presence of gas  Presence of abdominal pain  \\\n0                        0                1                           0   \n1                        1                1                           1   \n2                        1                0                           0   \n3                        0                0                           1   \n4                        1                0                           1   \n...                    ...              ...                         ...   \n9226                     1                1                           1   \n9227                     0                1                           1   \n9228                     1                0                           0   \n9229                     0                1                           1   \n9230                     0                0                           1   \n\n      Difficult digestion  ...  Personalized recipes_SHAP  \\\n0                       1  ...                   0.175097   \n1                       1  ...                   0.153504   \n2                       1  ...                  -0.265997   \n3                       1  ...                  -0.050389   \n4                       0  ...                  -0.199303   \n...                   ...  ...                        ...   \n9226                    1  ...                  -0.075381   \n9227                    0  ...                   0.176715   \n9228                    0  ...                  -0.082854   \n9229                    0  ...                   0.020888   \n9230                    0  ...                  -0.031396   \n\n      Supplement products_SHAP  Supplement timings_SHAP  Medications_SHAP  \\\n0                     0.102571                 0.006817         -0.155934   \n1                     0.018883                 0.091683          0.027926   \n2                    -0.115849                -0.076116         -0.002887   \n3                     0.013025                -0.045202          0.136049   \n4                     0.056505                -0.093204          0.034016   \n...                        ...                      ...               ...   \n9226                 -0.179279                -0.058356          0.004398   \n9227                  0.062678                 0.011333         -0.275734   \n9228                 -0.148825                 0.020241         -0.097088   \n9229                 -0.156151                -0.081750          0.041260   \n9230                 -0.139296                -0.080003          0.123975   \n\n      Gut_Health_Score  Diet_Quality_Score  Metabolic_Risk_Score  \\\n0                    3                  11             40.360339   \n1                    6                  14             33.030901   \n2                    1                  18             33.625061   \n3                    3                  23             28.205600   \n4                    0                  22             28.508270   \n...                ...                 ...                   ...   \n9226                 7                  28             30.248196   \n9227                 5                  21             22.095200   \n9228                 4                  30             33.551950   \n9229                 2                  21             45.063181   \n9230                 1                  22             30.509630   \n\n      Lifestyle_Balance_Index  Supplement_Compliance_Score  Genetic_Risk_Score  \n0                         2.7                            2            0.211180  \n1                         5.4                            0            0.154682  \n2                         6.4                            0           -0.289560  \n3                         9.4                            1           -0.163127  \n4                         3.5                            0           -0.014217  \n...                       ...                          ...                 ...  \n9226                      1.1                            1            0.100333  \n9227                      6.9                            0           -0.150588  \n9228                      6.9                            0           -0.093351  \n9229                     13.0                            1            0.030363  \n9230                      9.8                            2            0.003290  \n\n[9231 rows x 59 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Height (cm)</th>\n      <th>Weight (kg)</th>\n      <th>BMI</th>\n      <th>Previous gastrointestinal issues</th>\n      <th>Frequency of bowel movements</th>\n      <th>Stool consistency (Bristol scale)</th>\n      <th>Presence of bloating</th>\n      <th>Presence of gas</th>\n      <th>Presence of abdominal pain</th>\n      <th>Difficult digestion</th>\n      <th>...</th>\n      <th>Personalized recipes_SHAP</th>\n      <th>Supplement products_SHAP</th>\n      <th>Supplement timings_SHAP</th>\n      <th>Medications_SHAP</th>\n      <th>Gut_Health_Score</th>\n      <th>Diet_Quality_Score</th>\n      <th>Metabolic_Risk_Score</th>\n      <th>Lifestyle_Balance_Index</th>\n      <th>Supplement_Compliance_Score</th>\n      <th>Genetic_Risk_Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>173</td>\n      <td>120</td>\n      <td>40.1</td>\n      <td>1</td>\n      <td>6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.175097</td>\n      <td>0.102571</td>\n      <td>0.006817</td>\n      <td>-0.155934</td>\n      <td>3</td>\n      <td>11</td>\n      <td>40.360339</td>\n      <td>2.7</td>\n      <td>2</td>\n      <td>0.211180</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>183</td>\n      <td>110</td>\n      <td>32.8</td>\n      <td>0</td>\n      <td>18</td>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.153504</td>\n      <td>0.018883</td>\n      <td>0.091683</td>\n      <td>0.027926</td>\n      <td>6</td>\n      <td>14</td>\n      <td>33.030901</td>\n      <td>5.4</td>\n      <td>0</td>\n      <td>0.154682</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>170</td>\n      <td>97</td>\n      <td>33.6</td>\n      <td>1</td>\n      <td>17</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>-0.265997</td>\n      <td>-0.115849</td>\n      <td>-0.076116</td>\n      <td>-0.002887</td>\n      <td>1</td>\n      <td>18</td>\n      <td>33.625061</td>\n      <td>6.4</td>\n      <td>0</td>\n      <td>-0.289560</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>163</td>\n      <td>75</td>\n      <td>28.2</td>\n      <td>1</td>\n      <td>21</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>-0.050389</td>\n      <td>0.013025</td>\n      <td>-0.045202</td>\n      <td>0.136049</td>\n      <td>3</td>\n      <td>23</td>\n      <td>28.205600</td>\n      <td>9.4</td>\n      <td>1</td>\n      <td>-0.163127</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>172</td>\n      <td>85</td>\n      <td>28.7</td>\n      <td>0</td>\n      <td>20</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-0.199303</td>\n      <td>0.056505</td>\n      <td>-0.093204</td>\n      <td>0.034016</td>\n      <td>0</td>\n      <td>22</td>\n      <td>28.508270</td>\n      <td>3.5</td>\n      <td>0</td>\n      <td>-0.014217</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9226</th>\n      <td>187</td>\n      <td>107</td>\n      <td>30.6</td>\n      <td>1</td>\n      <td>15</td>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>-0.075381</td>\n      <td>-0.179279</td>\n      <td>-0.058356</td>\n      <td>0.004398</td>\n      <td>7</td>\n      <td>28</td>\n      <td>30.248196</td>\n      <td>1.1</td>\n      <td>1</td>\n      <td>0.100333</td>\n    </tr>\n    <tr>\n      <th>9227</th>\n      <td>172</td>\n      <td>67</td>\n      <td>22.6</td>\n      <td>0</td>\n      <td>19</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.176715</td>\n      <td>0.062678</td>\n      <td>0.011333</td>\n      <td>-0.275734</td>\n      <td>5</td>\n      <td>21</td>\n      <td>22.095200</td>\n      <td>6.9</td>\n      <td>0</td>\n      <td>-0.150588</td>\n    </tr>\n    <tr>\n      <th>9228</th>\n      <td>162</td>\n      <td>89</td>\n      <td>33.9</td>\n      <td>1</td>\n      <td>13</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-0.082854</td>\n      <td>-0.148825</td>\n      <td>0.020241</td>\n      <td>-0.097088</td>\n      <td>4</td>\n      <td>30</td>\n      <td>33.551950</td>\n      <td>6.9</td>\n      <td>0</td>\n      <td>-0.093351</td>\n    </tr>\n    <tr>\n      <th>9229</th>\n      <td>153</td>\n      <td>105</td>\n      <td>44.9</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.020888</td>\n      <td>-0.156151</td>\n      <td>-0.081750</td>\n      <td>0.041260</td>\n      <td>2</td>\n      <td>21</td>\n      <td>45.063181</td>\n      <td>13.0</td>\n      <td>1</td>\n      <td>0.030363</td>\n    </tr>\n    <tr>\n      <th>9230</th>\n      <td>198</td>\n      <td>120</td>\n      <td>30.6</td>\n      <td>1</td>\n      <td>12</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-0.031396</td>\n      <td>-0.139296</td>\n      <td>-0.080003</td>\n      <td>0.123975</td>\n      <td>1</td>\n      <td>22</td>\n      <td>30.509630</td>\n      <td>9.8</td>\n      <td>2</td>\n      <td>0.003290</td>\n    </tr>\n  </tbody>\n</table>\n<p>9231 rows × 59 columns</p>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"X_train1=df1.drop(columns=['Microbiota_status_ranked'])\ny_train1=df1['Microbiota_status_ranked']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T08:02:57.982303Z","iopub.execute_input":"2025-05-16T08:02:57.982593Z","iopub.status.idle":"2025-05-16T08:02:57.987816Z","shell.execute_reply.started":"2025-05-16T08:02:57.982574Z","shell.execute_reply":"2025-05-16T08:02:57.987068Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_train1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T08:03:01.985532Z","iopub.execute_input":"2025-05-16T08:03:01.986252Z","iopub.status.idle":"2025-05-16T08:03:02.005013Z","shell.execute_reply.started":"2025-05-16T08:03:01.986227Z","shell.execute_reply":"2025-05-16T08:03:02.004389Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nsm = SMOTE(random_state=42)\nX_balanced, y_balanced = sm.fit_resample(X_scaled, y_train1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T08:03:03.732823Z","iopub.execute_input":"2025-05-16T08:03:03.733384Z","iopub.status.idle":"2025-05-16T08:03:03.917579Z","shell.execute_reply.started":"2025-05-16T08:03:03.733357Z","shell.execute_reply":"2025-05-16T08:03:03.916921Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"y_balanced.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T08:03:05.793299Z","iopub.execute_input":"2025-05-16T08:03:05.793659Z","iopub.status.idle":"2025-05-16T08:03:05.801004Z","shell.execute_reply.started":"2025-05-16T08:03:05.793636Z","shell.execute_reply":"2025-05-16T08:03:05.800444Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Microbiota_status_ranked\n2    4381\n0    4381\n1    4381\nName: count, dtype: int64"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"df = pd.DataFrame(X_balanced)\ndf[\"Microbiota_status_ranked\"] = y_balanced.values.astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T08:28:42.678536Z","iopub.execute_input":"2025-05-16T08:28:42.679051Z","iopub.status.idle":"2025-05-16T08:28:42.684378Z","shell.execute_reply.started":"2025-05-16T08:28:42.679027Z","shell.execute_reply":"2025-05-16T08:28:42.683525Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"df[\"Microbiota_status_ranked\"] = df[\"Microbiota_status_ranked\"].map({\n    0: \"optimal\",\n    1: \"suboptimal\",\n    2: \"at risk\"\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T08:29:38.878129Z","iopub.execute_input":"2025-05-16T08:29:38.878683Z","iopub.status.idle":"2025-05-16T08:29:38.884764Z","shell.execute_reply.started":"2025-05-16T08:29:38.878660Z","shell.execute_reply":"2025-05-16T08:29:38.883968Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T08:29:41.701494Z","iopub.execute_input":"2025-05-16T08:29:41.701763Z","iopub.status.idle":"2025-05-16T08:29:41.723872Z","shell.execute_reply.started":"2025-05-16T08:29:41.701744Z","shell.execute_reply":"2025-05-16T08:29:41.723235Z"}},"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"              0         1         2         3         4         5         6  \\\n0     -0.129578  1.704910  1.416823  0.987191 -1.417773 -1.021038 -1.011659   \n1      0.543730  1.252106  0.594760 -1.012976  1.017293  0.975721  0.988475   \n2     -0.331570  0.663461  0.684849  0.987191  0.814370 -0.022658  0.988475   \n3     -0.802886 -0.332709  0.076748  0.987191  1.626059 -1.520227 -1.011659   \n4     -0.196908  0.120095  0.133054 -1.012976  1.423137  1.474910  0.988475   \n...         ...       ...       ...       ...       ...       ...       ...   \n13138 -1.202010  0.402978  1.069580 -0.476837  0.651192 -0.753425  0.452345   \n13139 -0.330456 -1.074270 -0.800702  0.610091 -0.403162  0.881607  0.988475   \n13140  0.831928  1.325439  0.481724  0.876462 -0.290825  0.948086 -1.011659   \n13141 -1.388329 -0.493117  0.270713  0.063356 -0.012789 -0.597967 -0.087839   \n13142 -1.380361  1.410866  2.267662 -1.012976  0.683029 -0.950602 -1.011659   \n\n              7         8         9  ...        49        50        51  \\\n0      1.027348 -0.999458  1.002060  ...  1.223503  0.294324 -1.007874   \n1      1.027348  1.000542  1.002060  ...  0.431972  1.883484  0.375730   \n2     -0.973380 -0.999458  1.002060  ... -0.842336 -1.258625  0.143850   \n3     -0.973380  1.000542  1.002060  ...  0.376567 -0.679755  1.189384   \n4     -0.973380  1.000542 -0.997944  ...  0.787803 -1.578607  0.421560   \n...         ...       ...       ...  ...       ...       ...       ...   \n13138 -0.437090  1.000542 -0.997944  ...  2.148390  1.017932  1.653099   \n13139  0.650143 -0.622390 -0.997944  ...  0.013320  0.558463  0.048899   \n13140 -0.862620 -0.999458  0.891341  ...  0.113923  1.267222  0.706930   \n13141  1.027348 -0.999458 -0.997944  ...  1.978168  0.427206  1.683989   \n13142  1.027348 -0.999458 -0.997944  ...  0.201241  0.812322  0.396743   \n\n             52        53        54        55        56        57  \\\n0     -0.471585 -1.923763  1.452935 -1.152204  1.418747  2.087429   \n1      0.487833 -1.401799  0.627773 -0.504868 -1.415063  1.614946   \n2     -1.111197 -0.705847  0.694664 -0.265114 -1.415063 -2.100162   \n3     -0.471585  0.164093  0.084531  0.454148  0.001842 -1.042829   \n4     -1.431004 -0.009895  0.118606 -0.960401 -1.415063  0.202480   \n...         ...       ...       ...       ...       ...       ...   \n13138  1.104359 -1.156054  1.104288  0.261849  1.418747  1.238214   \n13139  1.586175  0.282450 -0.780868 -1.510857 -0.265293  1.127381   \n13140 -0.187188  1.517469  0.490548  1.272220  0.001842  1.673997   \n13141  0.192410  0.846779  0.313418 -0.103088  0.764308 -0.149646   \n13142 -0.358773  1.332909  2.288349 -0.832873  0.001842  1.791326   \n\n       Microbiota_status_ranked  \n0                       at risk  \n1                       optimal  \n2                       optimal  \n3                       optimal  \n4                    suboptimal  \n...                         ...  \n13138                   at risk  \n13139                   at risk  \n13140                   at risk  \n13141                   at risk  \n13142                   at risk  \n\n[13143 rows x 59 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>49</th>\n      <th>50</th>\n      <th>51</th>\n      <th>52</th>\n      <th>53</th>\n      <th>54</th>\n      <th>55</th>\n      <th>56</th>\n      <th>57</th>\n      <th>Microbiota_status_ranked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.129578</td>\n      <td>1.704910</td>\n      <td>1.416823</td>\n      <td>0.987191</td>\n      <td>-1.417773</td>\n      <td>-1.021038</td>\n      <td>-1.011659</td>\n      <td>1.027348</td>\n      <td>-0.999458</td>\n      <td>1.002060</td>\n      <td>...</td>\n      <td>1.223503</td>\n      <td>0.294324</td>\n      <td>-1.007874</td>\n      <td>-0.471585</td>\n      <td>-1.923763</td>\n      <td>1.452935</td>\n      <td>-1.152204</td>\n      <td>1.418747</td>\n      <td>2.087429</td>\n      <td>at risk</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.543730</td>\n      <td>1.252106</td>\n      <td>0.594760</td>\n      <td>-1.012976</td>\n      <td>1.017293</td>\n      <td>0.975721</td>\n      <td>0.988475</td>\n      <td>1.027348</td>\n      <td>1.000542</td>\n      <td>1.002060</td>\n      <td>...</td>\n      <td>0.431972</td>\n      <td>1.883484</td>\n      <td>0.375730</td>\n      <td>0.487833</td>\n      <td>-1.401799</td>\n      <td>0.627773</td>\n      <td>-0.504868</td>\n      <td>-1.415063</td>\n      <td>1.614946</td>\n      <td>optimal</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.331570</td>\n      <td>0.663461</td>\n      <td>0.684849</td>\n      <td>0.987191</td>\n      <td>0.814370</td>\n      <td>-0.022658</td>\n      <td>0.988475</td>\n      <td>-0.973380</td>\n      <td>-0.999458</td>\n      <td>1.002060</td>\n      <td>...</td>\n      <td>-0.842336</td>\n      <td>-1.258625</td>\n      <td>0.143850</td>\n      <td>-1.111197</td>\n      <td>-0.705847</td>\n      <td>0.694664</td>\n      <td>-0.265114</td>\n      <td>-1.415063</td>\n      <td>-2.100162</td>\n      <td>optimal</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.802886</td>\n      <td>-0.332709</td>\n      <td>0.076748</td>\n      <td>0.987191</td>\n      <td>1.626059</td>\n      <td>-1.520227</td>\n      <td>-1.011659</td>\n      <td>-0.973380</td>\n      <td>1.000542</td>\n      <td>1.002060</td>\n      <td>...</td>\n      <td>0.376567</td>\n      <td>-0.679755</td>\n      <td>1.189384</td>\n      <td>-0.471585</td>\n      <td>0.164093</td>\n      <td>0.084531</td>\n      <td>0.454148</td>\n      <td>0.001842</td>\n      <td>-1.042829</td>\n      <td>optimal</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.196908</td>\n      <td>0.120095</td>\n      <td>0.133054</td>\n      <td>-1.012976</td>\n      <td>1.423137</td>\n      <td>1.474910</td>\n      <td>0.988475</td>\n      <td>-0.973380</td>\n      <td>1.000542</td>\n      <td>-0.997944</td>\n      <td>...</td>\n      <td>0.787803</td>\n      <td>-1.578607</td>\n      <td>0.421560</td>\n      <td>-1.431004</td>\n      <td>-0.009895</td>\n      <td>0.118606</td>\n      <td>-0.960401</td>\n      <td>-1.415063</td>\n      <td>0.202480</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13138</th>\n      <td>-1.202010</td>\n      <td>0.402978</td>\n      <td>1.069580</td>\n      <td>-0.476837</td>\n      <td>0.651192</td>\n      <td>-0.753425</td>\n      <td>0.452345</td>\n      <td>-0.437090</td>\n      <td>1.000542</td>\n      <td>-0.997944</td>\n      <td>...</td>\n      <td>2.148390</td>\n      <td>1.017932</td>\n      <td>1.653099</td>\n      <td>1.104359</td>\n      <td>-1.156054</td>\n      <td>1.104288</td>\n      <td>0.261849</td>\n      <td>1.418747</td>\n      <td>1.238214</td>\n      <td>at risk</td>\n    </tr>\n    <tr>\n      <th>13139</th>\n      <td>-0.330456</td>\n      <td>-1.074270</td>\n      <td>-0.800702</td>\n      <td>0.610091</td>\n      <td>-0.403162</td>\n      <td>0.881607</td>\n      <td>0.988475</td>\n      <td>0.650143</td>\n      <td>-0.622390</td>\n      <td>-0.997944</td>\n      <td>...</td>\n      <td>0.013320</td>\n      <td>0.558463</td>\n      <td>0.048899</td>\n      <td>1.586175</td>\n      <td>0.282450</td>\n      <td>-0.780868</td>\n      <td>-1.510857</td>\n      <td>-0.265293</td>\n      <td>1.127381</td>\n      <td>at risk</td>\n    </tr>\n    <tr>\n      <th>13140</th>\n      <td>0.831928</td>\n      <td>1.325439</td>\n      <td>0.481724</td>\n      <td>0.876462</td>\n      <td>-0.290825</td>\n      <td>0.948086</td>\n      <td>-1.011659</td>\n      <td>-0.862620</td>\n      <td>-0.999458</td>\n      <td>0.891341</td>\n      <td>...</td>\n      <td>0.113923</td>\n      <td>1.267222</td>\n      <td>0.706930</td>\n      <td>-0.187188</td>\n      <td>1.517469</td>\n      <td>0.490548</td>\n      <td>1.272220</td>\n      <td>0.001842</td>\n      <td>1.673997</td>\n      <td>at risk</td>\n    </tr>\n    <tr>\n      <th>13141</th>\n      <td>-1.388329</td>\n      <td>-0.493117</td>\n      <td>0.270713</td>\n      <td>0.063356</td>\n      <td>-0.012789</td>\n      <td>-0.597967</td>\n      <td>-0.087839</td>\n      <td>1.027348</td>\n      <td>-0.999458</td>\n      <td>-0.997944</td>\n      <td>...</td>\n      <td>1.978168</td>\n      <td>0.427206</td>\n      <td>1.683989</td>\n      <td>0.192410</td>\n      <td>0.846779</td>\n      <td>0.313418</td>\n      <td>-0.103088</td>\n      <td>0.764308</td>\n      <td>-0.149646</td>\n      <td>at risk</td>\n    </tr>\n    <tr>\n      <th>13142</th>\n      <td>-1.380361</td>\n      <td>1.410866</td>\n      <td>2.267662</td>\n      <td>-1.012976</td>\n      <td>0.683029</td>\n      <td>-0.950602</td>\n      <td>-1.011659</td>\n      <td>1.027348</td>\n      <td>-0.999458</td>\n      <td>-0.997944</td>\n      <td>...</td>\n      <td>0.201241</td>\n      <td>0.812322</td>\n      <td>0.396743</td>\n      <td>-0.358773</td>\n      <td>1.332909</td>\n      <td>2.288349</td>\n      <td>-0.832873</td>\n      <td>0.001842</td>\n      <td>1.791326</td>\n      <td>at risk</td>\n    </tr>\n  </tbody>\n</table>\n<p>13143 rows × 59 columns</p>\n</div>"},"metadata":{}}],"execution_count":66},{"cell_type":"code","source":"# STEP 2: Imports\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom tab_transformer_pytorch import TabTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, accuracy_score, log_loss\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T08:29:23.571298Z","iopub.execute_input":"2025-05-16T08:29:23.571549Z","iopub.status.idle":"2025-05-16T08:29:23.576509Z","shell.execute_reply.started":"2025-05-16T08:29:23.571532Z","shell.execute_reply":"2025-05-16T08:29:23.575719Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"!pip install pytorch-tabular[all] --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T08:12:55.452740Z","iopub.execute_input":"2025-05-16T08:12:55.452995Z","iopub.status.idle":"2025-05-16T08:12:58.865240Z","shell.execute_reply.started":"2025-05-16T08:12:55.452978Z","shell.execute_reply":"2025-05-16T08:12:58.864532Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: pytorch-tabular 1.1.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"le = LabelEncoder()\ndf[\"target\"] = le.fit_transform(df[\"Microbiota_status_ranked\"])\n\n# Drop string label column\ndf = df.drop(columns=[\"Microbiota_status_ranked\"])\n\n# Split features and target\nX = df.drop(columns=[\"target\"]).values\ny = df[\"target\"].values\n\n# Train-test split\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, stratify=y, random_state=42\n)\n\nn_features = X_train.shape[1]\nn_classes = len(np.unique(y))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T08:31:02.534045Z","iopub.execute_input":"2025-05-16T08:31:02.534770Z","iopub.status.idle":"2025-05-16T08:31:02.555357Z","shell.execute_reply.started":"2025-05-16T08:31:02.534740Z","shell.execute_reply":"2025-05-16T08:31:02.554784Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"# STEP 4: Dataset and DataLoader\nclass NumericDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = torch.tensor(X, dtype=torch.float32)\n        self.y = torch.tensor(y, dtype=torch.long)\n\n    def __len__(self): return len(self.y)\n    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n\ntrain_ds = NumericDataset(X_train, y_train)\nval_ds = NumericDataset(X_val, y_val)\n\ntrain_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=256)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T08:31:10.626551Z","iopub.execute_input":"2025-05-16T08:31:10.626825Z","iopub.status.idle":"2025-05-16T08:31:10.633205Z","shell.execute_reply.started":"2025-05-16T08:31:10.626805Z","shell.execute_reply":"2025-05-16T08:31:10.632629Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"# STEP 5: TabTransformer Model Initialization\nmodel = TabTransformer(\n    categories=(),                  # No categorical inputs\n    num_continuous=n_features,     # Number of numeric features (57)\n    dim=32,\n    dim_out=n_classes,             # 3-class classification\n    depth=6,\n    heads=8,\n    attn_dropout=0.1,\n    ff_dropout=0.1,\n    mlp_hidden_mults=(4, 2),\n    mlp_act=nn.ReLU(),\n    continuous_mean_std=None       # Already normalized\n).to(device)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.CrossEntropyLoss()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T08:31:20.711971Z","iopub.execute_input":"2025-05-16T08:31:20.712712Z","iopub.status.idle":"2025-05-16T08:31:20.732474Z","shell.execute_reply.started":"2025-05-16T08:31:20.712689Z","shell.execute_reply":"2025-05-16T08:31:20.731949Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"# STEP 6: Training Loop\nn_epochs = 20\nfor epoch in range(1, n_epochs + 1):\n    model.train()\n    total_loss = 0\n    for xb, yb in tqdm(train_loader, desc=f\"Epoch {epoch}\", leave=False):\n        xb, yb = xb.to(device), yb.to(device)\n        empty_cat = torch.empty(xb.size(0), 0, dtype=torch.long).to(device)\n        optimizer.zero_grad()\n        logits = model(x_categ=empty_cat, x_cont=xb)\n        loss = criterion(logits, yb)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * len(yb)\n\n    avg_loss = total_loss / len(train_ds)\n\n    # Validation accuracy\n    model.eval()\n    preds, targets = [], []\n    with torch.no_grad():\n        for xb, yb in val_loader:\n            xb = xb.to(device)\n            empty_cat = torch.empty(xb.size(0), 0, dtype=torch.long).to(device)\n            logits = model(x_categ=empty_cat, x_cont=xb)\n            preds.append(logits.argmax(1).cpu())\n            targets.append(yb)\n    y_pred = torch.cat(preds)\n    y_true = torch.cat(targets)\n    acc = accuracy_score(y_true, y_pred)\n    print(f\"Epoch {epoch:02d} | Train Loss: {avg_loss:.4f} | Val Acc: {acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T08:31:31.613815Z","iopub.execute_input":"2025-05-16T08:31:31.614394Z","iopub.status.idle":"2025-05-16T08:31:37.021073Z","shell.execute_reply.started":"2025-05-16T08:31:31.614371Z","shell.execute_reply":"2025-05-16T08:31:37.020351Z"}},"outputs":[{"name":"stderr","text":"                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 01 | Train Loss: 0.6775 | Val Acc: 0.6455\n","output_type":"stream"},{"name":"stderr","text":"                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 02 | Train Loss: 0.5272 | Val Acc: 0.6436\n","output_type":"stream"},{"name":"stderr","text":"                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 03 | Train Loss: 0.4926 | Val Acc: 0.6546\n","output_type":"stream"},{"name":"stderr","text":"                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 04 | Train Loss: 0.4711 | Val Acc: 0.6561\n","output_type":"stream"},{"name":"stderr","text":"                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 05 | Train Loss: 0.4538 | Val Acc: 0.6599\n","output_type":"stream"},{"name":"stderr","text":"                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 06 | Train Loss: 0.4375 | Val Acc: 0.6645\n","output_type":"stream"},{"name":"stderr","text":"                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 07 | Train Loss: 0.4207 | Val Acc: 0.6531\n","output_type":"stream"},{"name":"stderr","text":"                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 08 | Train Loss: 0.4013 | Val Acc: 0.6660\n","output_type":"stream"},{"name":"stderr","text":"                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 09 | Train Loss: 0.3806 | Val Acc: 0.6691\n","output_type":"stream"},{"name":"stderr","text":"                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10 | Train Loss: 0.3664 | Val Acc: 0.6630\n","output_type":"stream"},{"name":"stderr","text":"                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11 | Train Loss: 0.3421 | Val Acc: 0.6577\n","output_type":"stream"},{"name":"stderr","text":"                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12 | Train Loss: 0.3230 | Val Acc: 0.6660\n","output_type":"stream"},{"name":"stderr","text":"                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13 | Train Loss: 0.3007 | Val Acc: 0.6657\n","output_type":"stream"},{"name":"stderr","text":"                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14 | Train Loss: 0.2678 | Val Acc: 0.6736\n","output_type":"stream"},{"name":"stderr","text":"                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15 | Train Loss: 0.2483 | Val Acc: 0.6649\n","output_type":"stream"},{"name":"stderr","text":"                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16 | Train Loss: 0.2185 | Val Acc: 0.6554\n","output_type":"stream"},{"name":"stderr","text":"                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17 | Train Loss: 0.2008 | Val Acc: 0.6649\n","output_type":"stream"},{"name":"stderr","text":"                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18 | Train Loss: 0.1728 | Val Acc: 0.6641\n","output_type":"stream"},{"name":"stderr","text":"                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19 | Train Loss: 0.1537 | Val Acc: 0.6668\n","output_type":"stream"},{"name":"stderr","text":"                                                          ","output_type":"stream"},{"name":"stdout","text":"Epoch 20 | Train Loss: 0.1271 | Val Acc: 0.6679\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":70}]}